{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Example inference pipeline**\n",
    "This notebook infers lineages from the [Briney et al. 2019](https://doi.org/10.1038/s41586-019-0879-y) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Download data  \n",
    "Annotated data can be downloaded using links provided in the [briney/grp_paper repository](https://github.com/briney/grp_paper).  \n",
    "Uncomment following two lines to download all data in `./data/`  folder (make sure your current working directory is `.../HILARy/`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-17 16:07:38--  http://burtonlab.s3.amazonaws.com/sequencing-data/hiseq_2016-supplement/316188_HNCHNBCXY_consensus_UID18-cdr3nt-90_minimal_071817.tar.gz\n",
      "Resolving burtonlab.s3.amazonaws.com (burtonlab.s3.amazonaws.com)... 54.231.166.217, 52.216.212.241, 52.217.139.41, ...\n",
      "Connecting to burtonlab.s3.amazonaws.com (burtonlab.s3.amazonaws.com)|54.231.166.217|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3551933919 (3,3G) [application/x-tar]\n",
      "Saving to: ‘316188_HNCHNBCXY_consensus_UID18-cdr3nt-90_minimal_071817.tar.gz’\n",
      "\n",
      "316188_HNCHNBCXY_co 100%[===================>]   3,31G  32,0MB/s    in 3m 5s   \n",
      "\n",
      "2024-02-17 16:10:42 (18,4 MB/s) - ‘316188_HNCHNBCXY_consensus_UID18-cdr3nt-90_minimal_071817.tar.gz’ saved [3551933919/3551933919]\n",
      "\n",
      "consensus-cdr3nt-90_minimal/\n",
      "consensus-cdr3nt-90_minimal/14_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/6_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/3_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/15_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/16_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/7_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/18_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/10_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/1_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/11_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/9_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/4_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/5_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/8_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/12_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/17_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/2_consensus.txt\n",
      "consensus-cdr3nt-90_minimal/13_consensus.txt\n"
     ]
    }
   ],
   "source": [
    "#!wget http://burtonlab.s3.amazonaws.com/sequencing-data/hiseq_2016-supplement/316188_HNCHNBCXY_consensus_UID18-cdr3nt-90_minimal_071817.tar.gz\n",
    "#!tar -xvf 316188_HNCHNBCXY_consensus_UID18-cdr3nt-90_minimal_071817.tar.gz --directory data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert Briney data into airr format required by Hilary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for os\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/gathenes/.pyenv/versions/3.9.6/envs/hilary/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (4.66.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/gathenes/.pyenv/versions/3.9.6/envs/hilary/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/gathenes/.pyenv/versions/3.9.6/envs/hilary/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: biopython in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (1.83)\n",
      "Requirement already satisfied: numpy in /home/gathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from biopython) (1.26.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/gathenes/.pyenv/versions/3.9.6/envs/hilary/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install os\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install biopython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Process briney data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from hilary.utils import create_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [04:43<00:00, 15.76s/it]\n"
     ]
    }
   ],
   "source": [
    "from compatible import Compatible\n",
    "compatible = Compatible()\n",
    "usecols = [\n",
    "    \"seq_id\",\n",
    "    \"chain\",\n",
    "    \"productive\",\n",
    "    \"v_full\",\n",
    "    \"j_full\",\n",
    "    \"cdr3_nt\",\n",
    "    \"v_start\",\n",
    "    \"vdj_nt\",\n",
    "    \"isotype\",\n",
    "]\n",
    "dirname = \"./data/consensus-cdr3nt-90_minimal\"\n",
    "dfs = []\n",
    "for filename in tqdm(os.listdir(dirname)):\n",
    "    df = pd.read_csv(os.path.join(dirname, filename), usecols=usecols)\n",
    "    dfs.append(compatible.df2airr(df))\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df[\"sequence_id\"] = df.index\n",
    "filename = \"./data/316188_ids.tsv.gz\"\n",
    "df[[\"seq_id\", \"sequence_id\"]].to_csv(filename, sep=\"\\t\", index=False)\n",
    "df.drop(\"seq_id\", axis=1, inplace=True)\n",
    "filename = \"./data/316188.tsv.gz\"\n",
    "usecols = [\n",
    "    \"sequence_id\",\n",
    "    \"v_call\",\n",
    "    \"j_call\",\n",
    "    \"junction\",\n",
    "    \"v_sequence_alignment\",\n",
    "    \"j_sequence_alignment\",\n",
    "    \"v_germline_alignment\",\n",
    "    \"j_germline_alignment\",\n",
    "]\n",
    "df[usecols].to_csv(filename, sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = ['sequence_id',\n",
    "        'v_call',\n",
    "        'j_call',\n",
    "        'junction',\n",
    "        'v_sequence_alignment',\n",
    "        'j_sequence_alignment',\n",
    "        'v_germline_alignment',\n",
    "        'j_germline_alignment']\n",
    "filename = 'data/briney_dataset/316188.tsv.gz'\n",
    "dataframe = pd.read_table(filename,usecols=usecols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Package tutorial to infer lineages in python script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Uncomment next line to run on 100 000 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe=dataframe.head(100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create apriori object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hilary.apriori import Apriori\n",
    "apriori = Apriori(silent=False, threads=-1, precision=0.99, sensitivity=0.9) # show progress bars, use all threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7180/7180 [09:59<00:00, 11.98it/s]  \n"
     ]
    }
   ],
   "source": [
    "dataframe_processed = apriori.preprocess(df=dataframe, df_kappa=None)\n",
    "apriori.classes= create_classes(dataframe_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Infer histogram, parameters rho and mu, and sensitivity & precision thresholds for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 19:34:21 [debug    ] Computing CDR3 hamming distances within all large VJl classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4295/4295 [02:38<00:00, 27.04it/s] \n",
      "100%|██████████| 4295/4295 [00:15<00:00, 275.82it/s]\n",
      "100%|██████████| 83/83 [00:00<00:00, 88.63it/s] \n"
     ]
    }
   ],
   "source": [
    "apriori.get_histograms(dataframe_processed)\n",
    "apriori.get_parameters()\n",
    "apriori.get_thresholds()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create hilary object from apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hilary.inference import HILARy\n",
    "hilary=HILARy(apriori) # hilary.df is what is being updated by the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Compute precise and sensitive clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7180/7180 [00:08<00:00, 799.19it/s] \n",
      "100%|██████████| 7180/7180 [00:08<00:00, 832.18it/s] \n"
     ]
    }
   ],
   "source": [
    "dataframe_cdr3=hilary.compute_prec_sens_clusters(df=dataframe_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Infer clonal families from these clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 19:41:40 [debug    ] Checking alignment length.     alignment_length=271\n",
      "2024-02-17 19:41:40 [debug    ] Inferring family clusters for small groups.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3169/3169 [03:55<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 19:45:42 [debug    ] Inferring family clusters for large groups.\n"
     ]
    }
   ],
   "source": [
    "dataframe_inferred = hilary.infer(df=dataframe_cdr3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_inferred.to_csv(\"./data/results/briney_data/briney_families_new_1e3.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
