{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Example inference pipeline**\n",
    "This notebook infers lineages from the [Briney et al. 2019](https://doi.org/10.1038/s41586-019-0879-y) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Download data  \n",
    "Annotated data can be downloaded using links provided in the [briney/grp_paper repository](https://github.com/briney/grp_paper).  \n",
    "Uncomment following two lines to download all data in `./data/`  folder (make sure your current working directory is `.../HILARy/`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://burtonlab.s3.amazonaws.com/sequencing-data/hiseq_2016-supplement/316188_HNCHNBCXY_consensus_UID18-cdr3nt-90_minimal_071817.tar.gz\n",
    "#!tar -xvf 316188_HNCHNBCXY_consensus_UID18-cdr3nt-90_minimal_071817.tar.gz --directory data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert Briney data into airr format required by Hilary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: tqdm in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (4.66.1)\n",
      "Requirement already satisfied: pandas in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: biopython in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (1.82)\n",
      "Requirement already satisfied: numpy in /home/gabrielathenes/.pyenv/versions/3.9.6/envs/hilary/lib/python3.9/site-packages (from biopython) (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install os\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install biopython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Process briney data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [04:54<00:00, 16.39s/it]\n"
     ]
    }
   ],
   "source": [
    "from compatible import Compatible\n",
    "compatible = Compatible()\n",
    "usecols = [\n",
    "    \"seq_id\",\n",
    "    \"chain\",\n",
    "    \"productive\",\n",
    "    \"v_full\",\n",
    "    \"j_full\",\n",
    "    \"cdr3_nt\",\n",
    "    \"v_start\",\n",
    "    \"vdj_nt\",\n",
    "    \"isotype\",\n",
    "]\n",
    "dirname = \"./data/consensus-cdr3nt-90_minimal\"\n",
    "dfs = []\n",
    "for filename in tqdm(os.listdir(dirname)):\n",
    "    df = pd.read_csv(os.path.join(dirname, filename), usecols=usecols)\n",
    "    dfs.append(compatible.df2airr(df))\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df[\"sequence_id\"] = df.index\n",
    "filename = \"./data/316188_ids.tsv.gz\"\n",
    "df[[\"seq_id\", \"sequence_id\"]].to_csv(filename, sep=\"\\t\", index=False)\n",
    "df.drop(\"seq_id\", axis=1, inplace=True)\n",
    "filename = \"./data/316188.tsv.gz\"\n",
    "usecols = [\n",
    "    \"sequence_id\",\n",
    "    \"v_call\",\n",
    "    \"j_call\",\n",
    "    \"junction\",\n",
    "    \"v_sequence_alignment\",\n",
    "    \"j_sequence_alignment\",\n",
    "    \"v_germline_alignment\",\n",
    "    \"j_germline_alignment\",\n",
    "]\n",
    "df[usecols].to_csv(filename, sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = ['sequence_id',\n",
    "        'v_call',\n",
    "        'j_call',\n",
    "        'junction',\n",
    "        'v_sequence_alignment',\n",
    "        'j_sequence_alignment',\n",
    "        'v_germline_alignment',\n",
    "        'j_germline_alignment']\n",
    "filename = 'data/316188.tsv.gz'\n",
    "dataframe = pd.read_table(filename,usecols=usecols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Package tutorial to infer lineages in python script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Uncomment next line to run on 100 000 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=dataframe.head(100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create apriori object\n",
    "* Apriori class filters dataframe by removing sequences with :\n",
    "  - CDR3 length not multiple of three\n",
    "  - CDR3 length not in [15,81]\n",
    "  - More than 60 sequence mutations from germline\n",
    "  - A null column value\n",
    "* Stores this processed dataframe in `.df` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1390/1390 [00:05<00:00, 268.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:40:45 [debug    ] Filtering sequences            criteria_four=With a null column value. criteria_one=CDR3 length not multiple of three. criteria_three=More than 60 sequence mutations from germline. criteria_two=CDR3 length not in [15,81].\n"
     ]
    }
   ],
   "source": [
    "from hilary.apriori import Apriori\n",
    "apriori = Apriori(dataframe, silent=False)\n",
    "# apriori.df is a processed version of dataframe that the model is going to use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Infer histogram, parameters rho and mu, and sensitivity & precision thresholds for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:40:45 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:11<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:40:58 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 53/53 [00:11<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:41:10 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:12<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:41:23 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 60/60 [00:11<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:41:35 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:13<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:41:50 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:15<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:42:06 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 53/53 [00:11<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:42:19 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 60/60 [00:11<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:42:31 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:42:44 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:13<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:42:58 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 32/32 [00:06<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:43:05 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 33/33 [00:07<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:43:13 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 51/51 [00:10<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:43:25 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 49/49 [00:10<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:43:37 [debug    ] Computing CDR3 hamming distances within l class. CDR3_length=69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 36/36 [00:07<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:43:45 [debug    ] Computing CDR3 hamming distances within all large VJl classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:30<00:00,  1.32it/s]\n",
      "100%|██████████| 55/55 [00:09<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:44:26 [debug    ] Assigning effective prevalence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:44:32 [debug    ] Assigning effective mean distance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  4.86it/s]\n",
      "100%|██████████| 23/23 [00:04<00:00,  5.13it/s]\n"
     ]
    }
   ],
   "source": [
    "apriori.get_histograms()\n",
    "apriori.get_parameters()\n",
    "apriori.get_thresholds()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create hilary object from apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hilary.inference import HILARy\n",
    "hilary=HILARy(apriori) # hilary.df is what is being updated by the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Compute precise and sensitive clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1099/1099 [00:00<00:00, 1200.67it/s]\n",
      "100%|██████████| 1099/1099 [00:00<00:00, 1190.58it/s]\n"
     ]
    }
   ],
   "source": [
    "hilary.compute_prec_sens_clusters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Infer clonal families from these clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 11:48:02 [debug    ] Grouping precise clusters together to reach desired sensitivity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22880/22880 [2:19:56<00:00,  2.73it/s]       \n"
     ]
    }
   ],
   "source": [
    "hilary.infer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Update original dataframe with clonal families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~dataframe.index.isin(hilary.df.index) # Get sequences that have been removed in computations (non productive, null values ect)\n",
    "dataframe[\"family\"] = hilary.df[\"family\"] # Update filtered sequences with clonal families\n",
    "dataframe.loc[mask, \"family\"] = 0 # Label removed sequences with 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
